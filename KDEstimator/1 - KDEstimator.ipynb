{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“˜ Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any set of $M$ points ${x_1, x_2, ..., x_M}$ each of dimensionality $N$ follow some probability distribution $P(x)$. In many cases, the form of $P(x)$ is known and we only need to estimate its parameters (e.g., normal distribution with mean $\\mu$ and covariance $Î£$); however, in the general case the form of the distribution is unknown. Kernel density estimation helps us estimate $P(x)$ without assuming any form for it and while only using the available points ${x_1, x_2, ..., x_M}$.\n",
    "\n",
    "### âœ¦ Given\n",
    "Set of $M$ points ${x_1, x_2, ..., x_M}$ each of dimensionality $N$\n",
    "\n",
    "### âœ¦ Wanted \n",
    "An accurate estimate of the probability density function $P(x)$\n",
    "\n",
    "### âœ¦ Operation\n",
    "\n",
    "1. Choose a bump function $g(x)$ that integrates to $1$\n",
    "2. Choose a bandwidth $h$ that will control the spread of the bump function\n",
    "3. Estimate $P(x)$ as follows:\n",
    "Define\n",
    "$$Ï•(x)=\\frac{1}{h}g(\\frac{x}{h})   \\tag{1}$$ \n",
    "Then compute\n",
    "$$P(x) = \\frac{1}{M} \\sum_{m=1}^{M} \\phi(x-x_m) \\tag{2}$$\n",
    "\n",
    "\n",
    "**You are required to implement seven methods in `KDEstimator.py` where using any for loop is not allowed:**\n",
    "<br><br>\n",
    "```python\n",
    "__init__(self, bump='Gauss', bandwidth='Silverman')\n",
    "```\n",
    "- Sets the chosen bump function and bandwidth which can be that of `Silverman` or `Scott` (introduced below) or any positive real number\n",
    "<br><br>\n",
    "```python\n",
    "fit(self, x_train)\n",
    "```\n",
    "- Computes the bandwidth and stores the training data and its shape to be used later for the computation of $P(x)$\n",
    "- Both Silverman and Scott bandwidth rules of thumb will be considered in this function:\n",
    "\n",
    "Let\n",
    "$$ \\hat{\\sigma} = \\frac{1}{N} (\\sigma_1+\\sigma_2+...+\\sigma_N) $$\n",
    "\n",
    "Then Silverman's rule of thumb was among the optimal choice(s) covered in the lecture:\n",
    "\n",
    "$$ h = \\hat{\\sigma} \\cdot \\left( \\frac{4}{{M \\cdot (N+2)}} \\right)^{\\frac{1}{N+4}}$$\n",
    "\n",
    "Another rule of thumb is Scott's:\n",
    "\n",
    "$$ h = \\hat{\\sigma} â‹… M^{\\frac{-1}{N+4}}$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "```python\n",
    "g(self, x)\n",
    "```\n",
    "Implements $g(x)$ for the cases of a standard Gaussian and Rect bump function\n",
    "\n",
    "- Standard Gaussian\n",
    "$$g(\\mathbf{x}) = \\frac{1}{\\sqrt{(2\\pi)^N}} e^{-\\frac{1}{2} \\mathbf{x}^T \\mathbf{x}}$$\n",
    "\n",
    "- Rectangular\n",
    "\n",
    "$$ g(\\mathbf{x}) = \\begin{cases} 1 & \\text{if } -\\frac{1}{2} \\leq x_i \\leq \\frac{1}{2} \\:  \\forall_{i} \\\\ 0 & \\text{otherwise} \\end{cases}$$\n",
    "\n",
    "- The input assumed here is a numpy array of dimensions `(m,n)` and the output is a numpy array of dimensions `(m)` the evaluates the probability of each point.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "```python\n",
    "Ï•(self, x)\n",
    "```\n",
    "- Implements $\\phi$ as defined in $(1)$\n",
    "- Thanks to the fact that $g$ is vectorized, $Ï•(x-x_m)$ can be computed at once for all $x_m$ by passing them in a single numpy array\n",
    "\n",
    "<br><br>\n",
    "```python\n",
    "P(self, x)\n",
    "```\n",
    "- Implements $P$ as defined in $(2)$. The sum should be performed using Numpy for efficiency.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "```python\n",
    "transform(self, x_data)\n",
    "```\n",
    "- Applies $P(x)$ for each row in the given `(m,n)` numpy array `x_data` to return a numpy array `(m,)` of probabilities\n",
    "<br><br>\n",
    "\n",
    "\n",
    "```python\n",
    "fit_transform(self, x_data)\n",
    "```\n",
    "- Applies `fit` followed by `transform`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now go to KDEstimator.py and come back for tests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just some basic tests. Feel free to add more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# No need to restart the notebook upon change thanks to autoreload\n",
    "\n",
    "import numpy as np\n",
    "from KDEstimator import KDEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Scott and Silverman Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this data has standard deviation 1 along each column\n",
    "x_data= np.array([\n",
    "    [0, 2],\n",
    "    [2, 0],\n",
    "    [0, 2],\n",
    "    [2, 0]\n",
    "])\n",
    "\n",
    "# create two KDEstimator objects\n",
    "kde1 = KDEstimator(bump='Gauss', bandwidth='Silverman')\n",
    "kde2 = KDEstimator(bump='Gauss', bandwidth='Scott')\n",
    "\n",
    "# fit the data\n",
    "kde1.fit(x_data)\n",
    "kde2.fit(x_data)\n",
    "\n",
    "# TODO 1: Assume avg_Ïƒ=1; compute Silverman and Scott with calculator and assert their values\n",
    "calculated_silverman = None\n",
    "calculated_scott = None\n",
    "\n",
    "assert calculated_silverman == kde1.h\n",
    "assert calculated_scott == kde2.h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Gaussian Bump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "mean = np.zeros(2)  \n",
    "covariance = np.eye(2)  \n",
    "scipy_norm = multivariate_normal.pdf(x_data, mean=mean, cov=covariance)\n",
    "our_norm = kde1.g(x_data)\n",
    "\n",
    "# Test the implementation\n",
    "assert np.allclose(our_norm, scipy_norm, atol=1e-4), \"PDF values do not match expected values.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Rectangular Bump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.array([\n",
    "    [0, -0.6, 0.6],\n",
    "    [0, -0.3, 0.3],\n",
    "    [0.5, -0.5, 0.5],\n",
    "    [0, 0.1, 0.4],\n",
    "    [3, -2, 0]\n",
    "])\n",
    "kde1 = KDEstimator(bump='Rect', bandwidth='Silverman')\n",
    "assert np.all(kde1.g(x_val) == np.array([0, 1, 1, 1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Gaussian Kernel with Silverman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because Scipy computes the entire covariance matrix (doesn't make a standard normal assumption), we have allowed for a 1% error. This is also why we will skip testing a float bandwidth (but it should work anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "np.random.seed(42)\n",
    "x_data = np.random.rand(3000, 2)\n",
    "\n",
    "kde = KDEstimator(bump='Gauss', bandwidth='Silverman')\n",
    "kde.fit(x_data)\n",
    "my_res = kde.transform(x_data)\n",
    "\n",
    "kernel = gaussian_kde(x_data.T, bw_method='silverman')\n",
    "res = np.array(kernel(x_data.T))\n",
    "\n",
    "np.allclose(res, my_res, rtol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Gaussian Kernel with Scott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "x_data = np.random.rand(3000, 2)\n",
    "\n",
    "kde = KDEstimator(bump='Gauss', bandwidth='Scott')\n",
    "my_res = kde.fit_transform(x_data)\n",
    "\n",
    "kernel = gaussian_kde(x_data.T, bw_method='scott')\n",
    "res = np.array(kernel(x_data.T))\n",
    "\n",
    "np.allclose(res, my_res, rtol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Gaussian Kernel with Float Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should yield no error\n",
    "kde = KDEstimator(bump='Gauss', bandwidth=0.5)\n",
    "kde.fit(x_data)\n",
    "my_res = kde.transform(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ˜Ž Put on Your Machine Learning Engineer Glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d(x_data, *, densities, titles):\n",
    "    # TODO 2: Find min and max of x1 and x2 (first two columns of x_data)\n",
    "    x1_min, x1_max = None\n",
    "    x2_min, x2_max = None\n",
    "    \n",
    "    # TODO 3: Generate 100 points between min and max values for each dimension\n",
    "    x1 = None\n",
    "    x2 = None\n",
    "    \n",
    "    # TODO 4: Form a meshgrid from x1 and x2\n",
    "    x1, x2 = None\n",
    "    \n",
    "    # convert the meshgrid into a (m, n) array to allow evaluation by the model\n",
    "    x_plot = np.c_[x1.ravel(), x2.ravel()]\n",
    "    \n",
    "    # densities is a list of fitted kde instances.\n",
    "    # TODO 5: Form a list of probabilities evaluated from x_plot by each kde instance using list comprehension\n",
    "    z = None\n",
    "    \n",
    "    # put z in meshgrid shape as the plot function assumes that\n",
    "    z = [probs.reshape(x1.shape) for probs in z]\n",
    "    \n",
    "    # Number of subplots\n",
    "    num_subplots = len(titles)\n",
    "\n",
    "    # Creating subplots\n",
    "    plt.style.use('dark_background')\n",
    "    fig, axs = plt.subplots(1, num_subplots, figsize=(6 * num_subplots, 7), dpi=140, subplot_kw={'projection': '3d'})\n",
    "\n",
    "    # for each density we want a plot\n",
    "    for i, ax in enumerate(axs):\n",
    "        # TODO 6: Plot z[i] with x1 and x2\n",
    "        ax.plot_surface(None, None, None, cmap='plasma', alpha=0.8)\n",
    "        \n",
    "        # Set title and labels\n",
    "        ax.set_title(titles[i])\n",
    "        ax.set_xlabel('Feature X')\n",
    "        ax.set_ylabel('Feature Y')\n",
    "        ax.set_zlabel('Z-axis', labelpad=1)\n",
    "        # turn off grid and z-axis ticks\n",
    "        ax.grid(False)\n",
    "        ax.set_zticks([])\n",
    "        # turn off planes\n",
    "        ax.xaxis.pane.fill = False\n",
    "        ax.yaxis.pane.fill = False\n",
    "        ax.zaxis.pane.fill = False\n",
    "        # change view angle\n",
    "        ax.view_init(elev=50, azim=130)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compare the Choice of Bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random data\n",
    "x_data, _= datasets.make_blobs(n_samples=1000, centers=3, cluster_std=4.0, center_box=(-10,10), random_state=20)\n",
    "\n",
    "# TODO 7: Pass bandwidth of 0.1, 0.5, 1.0, 2.0, 10.9 to each following instantiation respectively\n",
    "\n",
    "kde1 = KDEstimator(bump='Gauss')\n",
    "kde1.fit(x_data)\n",
    "\n",
    "kde2 = KDEstimator(bump='Gauss')\n",
    "kde2.fit(x_data)\n",
    "\n",
    "kde3 = KDEstimator(bump='Gauss')\n",
    "kde3.fit(x_data)\n",
    "\n",
    "kde4 = KDEstimator(bump='Gauss')\n",
    "kde4.fit(x_data)\n",
    "\n",
    "kde5 = KDEstimator(bump='Gauss')\n",
    "kde5.fit(x_data)\n",
    "\n",
    "\n",
    "plot_3d(x_data, densities=[kde1, kde2, kde3, kde4, kde5], titles=['BW=0.1', 'BW=0.5', 'BW=1.0', 'BW=2.0', 'BW=10.0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "- Why does the estimate get smoother as we increase the bandwidth and get more discontinuous for vice versa?\n",
    "\n",
    "- Which of the following represents the most optimal choice in your opinion as someone who has seen real data densities before?\n",
    "\n",
    "- Which of these densities integrate to 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compare Scott and Silverman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 8: Pass bandwidth='Silverman' for kde1 and 'Scott' for kde2\n",
    "\n",
    "kde1 = KDEstimator(bump='Gauss')\n",
    "kde1.fit(x_data)\n",
    "\n",
    "kde2 = KDEstimator(bump='Gauss')\n",
    "kde2.fit(x_data)\n",
    "\n",
    "plot_3d(x_data, densities=[kde1, kde2], titles=['Silverman', 'Scott'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Extra] Read online (e.g., [here](https://stats.stackexchange.com/questions/90656/kernel-bandwidth-scotts-vs-silvermans-rules)) to deduce why there are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Answer goes here.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compare Bump Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 8: Pass bump='Gauss' for kde1 and 'Rect' for kde2\n",
    "\n",
    "kde1 = KDEstimator()\n",
    "kde1.fit(x_data)\n",
    "\n",
    "kde2 = KDEstimator()\n",
    "kde2.fit(x_data)\n",
    "\n",
    "plot_3d(x_data, densities=[kde1, kde2], titles=['Gaussian Bump', 'Rect Bump'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "- Why is the Rect bump more discontinuous?\n",
    "\n",
    "- What other density estimator is equivalent to using the rect bump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Answer goes here\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [TODO 9] Change the bandwidth setting for the Rect bump so that the density becomes smooth while remaining as close as possible to the Gaussian version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde1 = KDEstimator(bump='Gauss')\n",
    "kde1.fit(x_data)\n",
    "\n",
    "kde2 = KDEstimator(bump='Rect')\n",
    "kde2.fit(x_data)\n",
    "\n",
    "plot_3d(x_data, densities=[kde1, kde2], titles=['Gaussian Bump', 'Rect Bump'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfection ðŸ‘Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img width=\"1300\" src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExbGszZWVjM2RncGRhYnFhMnc5Z2h6ZmRxbzdyZTgwMHZqMDcycmplYyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/hWkg5NRbpwW9yIDV3r/giphy.gif\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
