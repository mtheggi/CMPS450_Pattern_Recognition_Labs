{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèãÔ∏è BMI Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will build a machine learning model to simulate health experts by classifying a given individual based on their height and weight into either one of <br><br> $BMI ‚àà {Extremly Weak, Weak, Normal, Overweight, Obese, Extremly Obese}$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Bayes Classification library that you implemented yourself for this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading the data from the local database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: Load the dataset\n",
    "dataset = None\n",
    "\n",
    "# Print the first 10 rows of the dataset\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike unstructured data (images, videos, etc.), structured data doesn't necessarily require feature extraction but surely requires data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: Print the number of missing values and drop them if any\n",
    "num_missing_vals = None\n",
    "\n",
    "# TODO 3: Rationally decide whether to keep or remove the 'Gender' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to horizontally split the data as `Scikit-learn` operates on seperate numpy arrays for the data and it's labels. We also need to vertically split the data into a training and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 4: Use Pandas to split dataset into target variable y_data (Index column) and features (rest of the columns) x_data\n",
    "y_data = None\n",
    "x_data = None\n",
    "\n",
    "# TODO 5: Split dataset into train and validation sets. Use 80% of the data for training and 20% for validation.  \n",
    "# Use random_state = 0 and stratify = y_data in your call to the train_test_split function\n",
    "x_data, y_data = x_data.to_numpy(), y_data.to_numpy()\n",
    "x_train, x_val, y_train, y_val = None\n",
    "# Think of how you would implement the line above using Numpy as you may be asked about that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define distinctive colors for the six classes\n",
    "classes = ['Extremely Weak', 'Weak', 'Normal', 'Overweight', 'Obese', 'Extremely Obese']\n",
    "colors = ['#999FFA', '#a52a2a', '#ffff00', '#5fff4a', '#f781bf', '#1199ff',]\n",
    "\n",
    "# Initiate plot\n",
    "plt.style.use('dark_background')            \n",
    "plt.figure(figsize=(8, 6), dpi=120)\n",
    "\n",
    "# Make a scatter plot for each class\n",
    "for i, label in enumerate(classes):\n",
    "    # TODO 6: extract data for the current class and scatter it\n",
    "    x_train_class = None\n",
    "    plt.scatter(None, None, color=colors[i], label=classes[i], s=10)\n",
    "\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Weight')\n",
    "plt.title('Scatter Plot of Height vs Weight')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice any problems in the this dataset? A problem in this content is defined as anything that would make classification harder for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Answer here\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 7: Rewrite the following code but using your own implementation. \n",
    "# Ideally, you should remove the Scikit learn code but you can keep it if you wish\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from BayesClassifier import BayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate\n",
    "gnb_model = GaussianNB()\n",
    "# Fit\n",
    "gnb_model.fit(x_train, y_train)\n",
    "# Predict\n",
    "gnb_y_pred = gnb_model.predict(x_val)\n",
    "# Evalute\n",
    "gnb_accuracy = gnb_model.score(x_val, y_val)\n",
    "print(\"Gaussian Naive Bayes Accuracy:\", gnb_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate\n",
    "lda_model = LinearDiscriminantAnalysis(solver='eigen')\n",
    "# Fit\n",
    "lda_model.fit(x_train, y_train)\n",
    "# Predict\n",
    "lda_y_pred = lda_model.predict(x_val)\n",
    "# Evaluate\n",
    "lda_accuracy = lda_model.score(x_val, y_val)\n",
    "print(\"Linear Discriminant Analysis Accuracy:\", lda_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_model = QuadraticDiscriminantAnalysis()\n",
    "qda_model.fit(x_train, y_train)\n",
    "qda_y_pred = qda_model.predict(x_val)\n",
    "qda_accuracy = qda_model.score(x_val, y_val)\n",
    "print(\"Quadratic Discriminant Analysis Accuracy:\", qda_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You won't be asked how the following code block works (exception) but comments explain it nonetheless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "# TODO 8: Put your trained QDA model here. Everything else is done for you.\n",
    "model = None\n",
    "\n",
    "# Sample data (assuming x_train is your training data)\n",
    "h = np.linspace(np.min(x_train[:, 0])-10, np.max(x_train[:, 0])+10, 300)\n",
    "w = np.linspace(np.min(x_train[:, 1])-10, np.max(x_train[:, 1])+10, 300)\n",
    "x, y = np.meshgrid(h, w)\n",
    "\n",
    "# For each pair (h, w) in the grid predict the labels by inputing (grid_size, 2) array of (h, w) into the model\n",
    "z_labels = qda_model.predict(np.c_[x.ravel(), y.ravel()])               # flatten x, y then concatenate\n",
    "# map array of labels to array of integers to represent different contour levels (colors)\n",
    "z = np.array([list(qda_model.labels).index(label) for label in z_labels])\n",
    "# reshape z into a grid\n",
    "z = z.reshape(x.shape)\n",
    "\n",
    "# Plot setupt\n",
    "plt.style.use('dark_background')\n",
    "plt.figure(figsize=(8, 6), dpi=120)\n",
    "colors = np.array(['#999FFA', '#a52a2a', '#ffff00', '#5fff4a', '#f781bf',   '#ff0000', '#1199ff',])\n",
    "\n",
    "# contour plot takes three grids and decides the color based on z (here it has integer labels)\n",
    "# just as if we are looking at a 3D plot from above\n",
    "plt.contourf(x, y, z, cmap=matplotlib.colors.ListedColormap(colors), alpha=0.8)  # Use colormap for classes\n",
    "\n",
    "# Scatter plot as done before\n",
    "unique_classes = np.unique(y_train)  \n",
    "for i, class_label in enumerate(unique_classes):\n",
    "    class_data = x_train[y_train == class_label]  \n",
    "    plt.scatter(class_data[:, 0], class_data[:, 1], label=class_label, edgecolor='black', s=40, c=colors[i if i!=5 else i+1]) # small bug here\n",
    "\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Weights\")\n",
    "plt.title(\"QDA Model - Decision Boundary\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Under the performance metrics above, map each of the images below to one of the models (write the name below it):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ![Image 1](https://i.imgur.com/8Ki7Y08.png) | ![Image 2](https://i.imgur.com/6urbPib.png) | ![Image 3](https://i.imgur.com/aEigNFd.png) |\n",
    "|:-----------------------:|:-----------------------:|:-----------------------:|\n",
    "|       Model X      |       Model Y      |       Model Z      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) It's known that height and weight of individuals follow a normal distribution. In light of that, explain why Model Z offered the best performance. Also, describe what violating assumptions did model X and model Y make that made them perform poorly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Answer goes here\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) (Bonus) In what situations do you think Model X or Model Y could be better than model Z?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Answer goes here\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://media1.giphy.com/media/j6rZ55Ffe46hRGf4WX/giphy.gif\" width=400>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
